{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0919 16:52:31.502038  9500 deprecation_wrapper.py:119] From C:\\Users\\Gachon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0919 16:52:31.514119  9500 deprecation_wrapper.py:119] From C:\\Users\\Gachon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0919 16:52:31.517063  9500 deprecation_wrapper.py:119] From C:\\Users\\Gachon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0919 16:52:31.533073  9500 deprecation_wrapper.py:119] From C:\\Users\\Gachon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0919 16:52:31.774375  9500 deprecation_wrapper.py:119] From C:\\Users\\Gachon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0919 16:52:31.774375  9500 deprecation_wrapper.py:119] From C:\\Users\\Gachon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n",
      "Found 88 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'F:\\\\datasets'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i+1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i+1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # 제너레이터는 루프 안에서 무한하게 데이터를 만들어내므로 모든 이미지를 한 번씩 처리하고 나면 중지합니다\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 500)\n",
    "test_features, test_labels = extract_features(test_dir, 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (500, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (88, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0919 16:53:46.918633  9500 deprecation.py:506] From C:\\Users\\Gachon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0919 16:53:46.941631  9500 deprecation_wrapper.py:119] From C:\\Users\\Gachon\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0919 16:53:46.946622  9500 deprecation.py:323] From C:\\Users\\Gachon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7307 - acc: 0.5260\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6734 - acc: 0.5940\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6485 - acc: 0.6220\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5919 - acc: 0.6840\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5837 - acc: 0.6680\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5473 - acc: 0.7080\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5394 - acc: 0.7200\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5121 - acc: 0.7400\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4948 - acc: 0.7560\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4943 - acc: 0.7380\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4630 - acc: 0.7960\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4715 - acc: 0.7840\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4553 - acc: 0.8000\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4440 - acc: 0.8100\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4411 - acc: 0.7900\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4393 - acc: 0.8120\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4176 - acc: 0.8180\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4198 - acc: 0.8140\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4060 - acc: 0.8140\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3925 - acc: 0.8380\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3882 - acc: 0.8420\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3979 - acc: 0.8420\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3681 - acc: 0.8420\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3654 - acc: 0.8540\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3627 - acc: 0.8580\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3611 - acc: 0.8640\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3491 - acc: 0.8600\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3416 - acc: 0.8620\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3405 - acc: 0.8720\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3382 - acc: 0.8600\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3304 - acc: 0.8760\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3243 - acc: 0.8840\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3164 - acc: 0.8820\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3137 - acc: 0.8920\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3033 - acc: 0.8960\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2999 - acc: 0.8900\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2974 - acc: 0.9000\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2939 - acc: 0.8920\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2974 - acc: 0.8920\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2994 - acc: 0.9020\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2938 - acc: 0.8960\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2821 - acc: 0.9020\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2746 - acc: 0.9120\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2688 - acc: 0.9200\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2775 - acc: 0.8980\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2708 - acc: 0.8940\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2648 - acc: 0.9060\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2650 - acc: 0.9100\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2534 - acc: 0.9140\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2591 - acc: 0.9280\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=50,\n",
    "                    batch_size=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_base를 동결하기 전 훈련되는 가중치의 수: 30\n"
     ]
    }
   ],
   "source": [
    "print('conv_base를 동결하기 전 훈련되는 가중치의 수:', \n",
    "      len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_base를 동결한 후 훈련되는 가중치의 수: 4\n"
     ]
    }
   ],
   "source": [
    "print('conv_base를 동결한 후 훈련되는 가중치의 수:', \n",
    "      len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      " - 224s - loss: 0.6222 - acc: 0.6635\n",
      "Epoch 2/10\n",
      " - 224s - loss: 0.5400 - acc: 0.7300\n",
      "Epoch 3/10\n",
      " - 224s - loss: 0.5041 - acc: 0.7555\n",
      "Epoch 4/10\n",
      " - 226s - loss: 0.4812 - acc: 0.7740\n",
      "Epoch 5/10\n",
      " - 225s - loss: 0.4562 - acc: 0.7850\n",
      "Epoch 6/10\n",
      " - 225s - loss: 0.4361 - acc: 0.7990\n",
      "Epoch 7/10\n",
      " - 223s - loss: 0.4170 - acc: 0.8170\n",
      "Epoch 8/10\n",
      " - 222s - loss: 0.4075 - acc: 0.8175\n",
      "Epoch 9/10\n",
      " - 222s - loss: 0.3942 - acc: 0.8240\n",
      "Epoch 10/10\n",
      " - 221s - loss: 0.3912 - acc: 0.8350\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.1,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# 검증 데이터는 증식되어서는 안 됩니다!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        train_dir,\n",
    "        # 모든 이미지의 크기를 150 × 150로 변경합니다\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # binary_crossentropy 손실을 사용하므로 이진 레이블이 필요합니다\n",
    "        class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=10,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('heartsound.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 269s 3s/step - loss: 0.3473 - acc: 0.8470\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 267s 3s/step - loss: 0.2705 - acc: 0.8845\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 266s 3s/step - loss: 0.2369 - acc: 0.8995\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.2099 - acc: 0.9125\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.1763 - acc: 0.9240\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.1530 - acc: 0.9355\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.1360 - acc: 0.9450\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.1189 - acc: 0.9540\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.1106 - acc: 0.9525\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.1029 - acc: 0.9590\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.0803 - acc: 0.9720\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0776 - acc: 0.9685\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0710 - acc: 0.9750\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0703 - acc: 0.9750\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0614 - acc: 0.9755\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0570 - acc: 0.9820\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0452 - acc: 0.9840\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.0380 - acc: 0.9895\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.0405 - acc: 0.9865\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0343 - acc: 0.9865\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0306 - acc: 0.9890\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.0311 - acc: 0.9895\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.0316 - acc: 0.9885\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0230 - acc: 0.9915\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0246 - acc: 0.9920\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0220 - acc: 0.9930\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0239 - acc: 0.9940\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 3585s 36s/step - loss: 0.0187 - acc: 0.9925\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0323 - acc: 0.9860\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0163 - acc: 0.9945\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0119 - acc: 0.9965\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0168 - acc: 0.9930\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0157 - acc: 0.9935\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0114 - acc: 0.9960\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0214 - acc: 0.9925\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0148 - acc: 0.9940\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0088 - acc: 0.9975\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0138 - acc: 0.9950\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 265s 3s/step - loss: 0.0066 - acc: 0.9980\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0124 - acc: 0.9950\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0083 - acc: 0.9965\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0113 - acc: 0.9955\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0044 - acc: 0.9995\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0117 - acc: 0.9960\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0097 - acc: 0.9960\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0112 - acc: 0.9965\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0106 - acc: 0.9955\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1725s 17s/step - loss: 0.0059 - acc: 0.9980\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 383s 4s/step - loss: 0.0086 - acc: 0.9975\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0032 - acc: 0.9995\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0071 - acc: 0.9965\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0079 - acc: 0.9970\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0057 - acc: 0.9990\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0059 - acc: 0.9985\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0043 - acc: 0.9985\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0057 - acc: 0.9980\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0070 - acc: 0.9970\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0063 - acc: 0.9975\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0038 - acc: 0.9985\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0082 - acc: 0.9970\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0034 - acc: 0.9985\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0054 - acc: 0.9985\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0094 - acc: 0.9975\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0042 - acc: 0.9980\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0049 - acc: 0.9990\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0016 - acc: 0.9995\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0027 - acc: 0.9990\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0065 - acc: 0.9970\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0027 - acc: 0.9995\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0044 - acc: 0.9975\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0034 - acc: 0.9990\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0065 - acc: 0.9980\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 7.7834e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 386s 4s/step - loss: 0.0114 - acc: 0.9980\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.0100 - acc: 0.9970\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0059 - acc: 0.9975\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0027 - acc: 0.9995\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 263s 3s/step - loss: 0.0040 - acc: 0.9990\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0051 - acc: 0.9980\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0020 - acc: 0.9990\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0066 - acc: 0.9980\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0050 - acc: 0.9980\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0045 - acc: 0.9980\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0045 - acc: 0.9980\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 7.9464e-04 - acc: 0.9995\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0027 - acc: 0.9990\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 5.8483e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0042 - acc: 0.9975\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0075 - acc: 0.9975\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0029 - acc: 0.9990\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0024 - acc: 0.9990\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 263s 3s/step - loss: 0.0025 - acc: 0.9995\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('heartsound2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 2 classes.\n",
      "test acc: 0.7954545446417548\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
